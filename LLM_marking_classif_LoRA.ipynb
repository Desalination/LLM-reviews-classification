{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 13079977,
          "sourceType": "datasetVersion",
          "datasetId": 8284257
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import Dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T23:57:02.608755Z",
          "iopub.execute_input": "2025-09-16T23:57:02.609265Z",
          "iopub.status.idle": "2025-09-16T23:57:29.639822Z",
          "shell.execute_reply.started": "2025-09-16T23:57:02.609240Z",
          "shell.execute_reply": "2025-09-16T23:57:29.639227Z"
        },
        "id": "6eNPKbVdHq08"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "kmmLSohiHq1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/kaggle/input/nlp-classif-datasets/train.csv\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/nlp-classif-datasets/test.csv\")\n",
        "categories = [\"бытовая техника\", \"обувь\", \"одежда\", \"посуда\",\n",
        "              \"текстиль\", \"товары для детей\", \"украшения и аксессуары\",\n",
        "              \"электроника\", \"нет товара\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T23:57:29.640991Z",
          "iopub.execute_input": "2025-09-16T23:57:29.641646Z",
          "iopub.status.idle": "2025-09-16T23:57:29.736059Z",
          "shell.execute_reply.started": "2025-09-16T23:57:29.641623Z",
          "shell.execute_reply": "2025-09-16T23:57:29.735230Z"
        },
        "id": "M8wWftwTHq1G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Инициализация zero-shot классификатора\n"
      ],
      "metadata": {
        "id": "F3wOuE1lHq1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-16T23:57:46.595318Z",
          "iopub.execute_input": "2025-09-16T23:57:46.595596Z",
          "iopub.status.idle": "2025-09-16T23:57:53.765216Z",
          "shell.execute_reply.started": "2025-09-16T23:57:46.595576Z",
          "shell.execute_reply": "2025-09-16T23:57:53.764549Z"
        },
        "id": "3rmvZAvoHq1I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Автоматическая разметка train-даты, train val split и формирование Dataset"
      ],
      "metadata": {
        "id": "Pck7bLZNHq1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_texts = train_df['text'].tolist()\n",
        "train_labels = []\n",
        "train_confidences = []\n",
        "\n",
        "for text in tqdm(train_texts):\n",
        "    res = classifier(text, candidate_labels=categories, multi_label=False)\n",
        "    label = res['labels'][0]\n",
        "    score = res['scores'][0]\n",
        "    # Присваиваем \"нет товара\", если уверенность слишком низка\n",
        "    if score < 0.5:\n",
        "        label = \"нет товара\"\n",
        "    train_labels.append(label)\n",
        "    train_confidences.append(score)\n",
        "\n",
        "# Добавляем разметку в датафрейм\n",
        "train_df['category'] = train_labels\n",
        "train_df['confidence'] = train_confidences\n",
        "\n",
        "# Преобразуем категории в числовые метки\n",
        "label2id = {cat: idx for idx, cat in enumerate(categories)}\n",
        "id2label = {idx: cat for cat, idx in label2id.items()}\n",
        "train_df['label'] = train_df['category'].map(label2id)\n",
        "\n",
        "# Сохраняем файл с разметкой\n",
        "train_df[['text', 'category', 'confidence']].to_csv(\"train_labeled.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"train_labeled.csv сохранён\")\n",
        "\n",
        "# Формируем Dataset для HuggingFace\n",
        "dataset = Dataset.from_pandas(train_df[['text','label']])\n",
        "dataset = dataset.train_test_split(test_size=0.2)  # 80% train, 20% val\n",
        "print(\"train data is marked up and saved\")\n"
      ],
      "metadata": {
        "id": "2-YIzjAkgdQL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-17T00:15:32.270064Z",
          "iopub.execute_input": "2025-09-17T00:15:32.270544Z",
          "iopub.status.idle": "2025-09-17T00:19:50.434049Z",
          "shell.execute_reply.started": "2025-09-17T00:15:32.270521Z",
          "shell.execute_reply": "2025-09-17T00:19:50.433259Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загружаем модель для классификации, конфигурация LoRA\n"
      ],
      "metadata": {
        "id": "_BxPhDBhHq1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model_name = \"DeepPavlov/rubert-base-cased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=len(categories), id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# Конфигурация LoRA\n",
        "peft_config = LoraConfig(\n",
        "    task_type=\"SEQ_CLS\",\n",
        "    inference_mode=False,\n",
        "    r=8, lora_alpha=32, lora_dropout=0.1,\n",
        "    target_modules=[\"query\", \"value\"]  # адаптеры в модулях attention\n",
        ")\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "RDf5UEz0gWOo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-17T00:02:11.665255Z",
          "iopub.execute_input": "2025-09-17T00:02:11.665607Z",
          "iopub.status.idle": "2025-09-17T00:02:17.064825Z",
          "shell.execute_reply.started": "2025-09-17T00:02:11.665580Z",
          "shell.execute_reply": "2025-09-17T00:02:17.064231Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Токенизация, метрики, параметры обучения"
      ],
      "metadata": {
        "id": "SqJJG1MSHq1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Функция для токенизации\n",
        "def preprocess(batch):\n",
        "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=256)\n",
        "\n",
        "train_encodings = dataset['train'].map(preprocess, batched=True)\n",
        "val_encodings = dataset['test'].map(preprocess, batched=True)\n",
        "\n",
        "# Функция вычисления метрик\n",
        "def compute_metrics(eval_pred):\n",
        "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
        "    f1 = f1_score(eval_pred.label_ids, preds, average='weighted')\n",
        "    return {\"weighted_f1\": f1}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"model_outut\",\n",
        "    num_train_epochs=20,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-4,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_dir=\"logs\",\n",
        "    disable_tqdm=False,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=100\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_encodings,\n",
        "    eval_dataset=val_encodings,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-17T00:02:17.065534Z",
          "iopub.execute_input": "2025-09-17T00:02:17.065781Z",
          "iopub.status.idle": "2025-09-17T00:02:19.827879Z",
          "shell.execute_reply.started": "2025-09-17T00:02:17.065763Z",
          "shell.execute_reply": "2025-09-17T00:02:19.827298Z"
        },
        "id": "ZnZQ5jTaHq1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение модели"
      ],
      "metadata": {
        "id": "71LcJZmDHq1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "print('Training')\n",
        "trainer.train()\n",
        "print('Trained')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-17T00:02:19.828619Z",
          "iopub.execute_input": "2025-09-17T00:02:19.828959Z",
          "iopub.status.idle": "2025-09-17T00:14:46.536180Z",
          "shell.execute_reply.started": "2025-09-17T00:02:19.828936Z",
          "shell.execute_reply": "2025-09-17T00:14:46.535393Z"
        },
        "id": "4Pf3rBDNHq1O",
        "outputId": "7e3a0a02-0f6b-4d09-a7bd-d5cdd4ca40d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='3640' max='3640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3640/3640 12:25, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Weighted F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.292000</td>\n      <td>1.040365</td>\n      <td>0.567869</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.936400</td>\n      <td>0.855897</td>\n      <td>0.625369</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.799100</td>\n      <td>0.760621</td>\n      <td>0.752629</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.653100</td>\n      <td>0.729918</td>\n      <td>0.750897</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.572800</td>\n      <td>0.738861</td>\n      <td>0.763773</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.523600</td>\n      <td>0.706752</td>\n      <td>0.764761</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.477700</td>\n      <td>0.793073</td>\n      <td>0.771045</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.452000</td>\n      <td>0.727988</td>\n      <td>0.779808</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.405400</td>\n      <td>0.798040</td>\n      <td>0.775634</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.335400</td>\n      <td>0.819023</td>\n      <td>0.777092</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.331900</td>\n      <td>0.820792</td>\n      <td>0.796913</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.269400</td>\n      <td>0.957032</td>\n      <td>0.778479</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.290500</td>\n      <td>0.892919</td>\n      <td>0.815222</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.241000</td>\n      <td>1.012855</td>\n      <td>0.779471</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.222000</td>\n      <td>0.992524</td>\n      <td>0.801273</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.198200</td>\n      <td>1.055929</td>\n      <td>0.790475</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.179900</td>\n      <td>1.036714</td>\n      <td>0.795716</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.202800</td>\n      <td>1.094942</td>\n      <td>0.789500</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.144200</td>\n      <td>1.131520</td>\n      <td>0.785600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.150100</td>\n      <td>1.127200</td>\n      <td>0.793903</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Trained\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "после 13 эпохи получена лучшая метрика weighted F1 = 0.815 на валидационной выборке. Поэтому выбираем веса модели после 13-й эпохи для предсказаний на тесте"
      ],
      "metadata": {
        "id": "LvussojPHq1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка лучшей версии модели"
      ],
      "metadata": {
        "id": "jUIRES26Hq1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# Путь к сохранённым весам после 13-й эпохи\n",
        "checkpoint_dir = \"/kaggle/working/model_output/checkpoint-3094\"\n",
        "\n",
        "# Загружаем токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\n",
        "\n",
        "# Загружаем базовую модель\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"DeepPavlov/rubert-base-cased\",\n",
        "    num_labels=len(categories),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Загружаем LoRA-конфигурацию и веса\n",
        "model = PeftModel.from_pretrained(base_model, checkpoint_dir)\n",
        "\n",
        "# Проверим, что всё загрузилось\n",
        "print(\"LoRA модель успешно загружена\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-17T00:22:45.235169Z",
          "iopub.execute_input": "2025-09-17T00:22:45.235430Z",
          "iopub.status.idle": "2025-09-17T00:22:47.317616Z",
          "shell.execute_reply.started": "2025-09-17T00:22:45.235412Z",
          "shell.execute_reply": "2025-09-17T00:22:47.317057Z"
        },
        "id": "mnSh_5ouHq1P"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предсказания для тестовой выборки"
      ],
      "metadata": {
        "id": "FASadwOkHq1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('predicting')\n",
        "# Предсказания на тестовом наборе\n",
        "test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n",
        "test_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'])\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "all_preds = []\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        inputs = {\"input_ids\": batch[0].cuda(), \"attention_mask\": batch[1].cuda()}\n",
        "        outputs = model(**inputs)\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "end.record()\n",
        "torch.cuda.synchronize()\n",
        "elapsed_time = start.elapsed_time(end) / len(test_df)  # среднее время на один пример (мс)\n",
        "print(f\"Avg inference time per example: {elapsed_time:.2f} ms\")\n",
        "\n",
        "# Создаём DataFrame с предсказаниями\n",
        "test_labels = [id2label[p] for p in all_preds]\n",
        "submission = pd.DataFrame({\"category\": test_labels})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print('predicted')\n",
        "print(\"THE END\")"
      ],
      "metadata": {
        "id": "j1z628XvgYwd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-17T00:27:11.383009Z",
          "iopub.execute_input": "2025-09-17T00:27:11.383994Z",
          "iopub.status.idle": "2025-09-17T00:27:38.307476Z",
          "shell.execute_reply.started": "2025-09-17T00:27:11.383963Z",
          "shell.execute_reply": "2025-09-17T00:27:38.306814Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccebc78-240b-44b0-f7e1-265efaec442a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 455/455 [00:53<00:00,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg inference time per example: 7.30 ms\n",
            "predicted\n",
            "THE END\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}
